{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess test and train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jun  3 18:25:19 2020\n",
    "\n",
    "@author: orestis\n",
    "\"\"\"\n",
    "\n",
    "from pandas import DataFrame,read_csv\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "#Location of train data\n",
    "TrainLocation = '/home/orestis/Desktop/GitHubRepositories/DataMining-MachineLearning/CommentsClassification/data/train.csv'\n",
    "#Location of test data\n",
    "TestLocation = '/home/orestis/Desktop/GitHubRepositories/DataMining-MachineLearning/CommentsClassification/data/test.csv'\n",
    "\n",
    "train_df = pd.read_csv(TrainLocation,names=['Class','Date','Comment'],skiprows=1)   #Get the training data\n",
    "test_df = pd.read_csv(TestLocation,names=['Class','Date','Comment'],skiprows=1)     #Get the testing data\n",
    "\n",
    "#Delete date column\n",
    "del train_df['Date']\n",
    "del test_df['Date']\n",
    "\n",
    "train_comments = train_df['Comment']\n",
    "test_comments = test_df['Comment']\n",
    "\n",
    "#PREPROCESS COMMENTS DATA\n",
    "alphabet = list(string.ascii_lowercase)\n",
    "numbers=['1','2','3','4','5','6','7','8','9','0',' ']\n",
    "alphabet = alphabet + numbers\n",
    "#Convert to lower case\n",
    "for i in range(len(train_comments)):\n",
    "    train_comments[i]=train_comments[i].lower()\n",
    "    train_comments[i] = train_comments[i].replace('-',' ')\n",
    "    train_comments[i] = train_comments[i].replace('\\\\',' ')\n",
    "    train_comments[i] = train_comments[i].replace('.',' ')\n",
    "    train_comments[i] = train_comments[i].replace(',',' ')\n",
    "    train_comments[i] = train_comments[i].replace('_',' ')\n",
    "    #Keep only the letters and numbers\n",
    "    for c in train_comments[i]:\n",
    "        if c not in alphabet:\n",
    "             train_comments[i]=train_comments[i].replace(c,'')\n",
    "\n",
    "for i in range(len(test_comments)):\n",
    "    test_comments[i]=test_comments[i].lower()\n",
    "    test_comments[i] = test_comments[i].replace('-',' ')\n",
    "    test_comments[i] = test_comments[i].replace('\\\\',' ')\n",
    "    test_comments[i] = test_comments[i].replace('.',' ')\n",
    "    test_comments[i] = test_comments[i].replace(',',' ')\n",
    "    test_comments[i] = test_comments[i].replace('_',' ')\n",
    "    #Keep only the letters and numbers\n",
    "    for c in test_comments[i]:\n",
    "        if c not in alphabet:\n",
    "             test_comments[i]=test_comments[i].replace(c,'')\n",
    "    \n",
    "train_class_values = train_df['Class']\n",
    "\n",
    "#Create the new data sets\n",
    "NewTrainDataSet = list(zip(train_comments,train_class_values))\n",
    "NewTestDataSet = list(test_comments)\n",
    "\n",
    "new_train_df = pd.DataFrame(data=NewTrainDataSet,columns=['Comments','Classs'])\n",
    "new_test_df = pd.DataFrame(data=NewTestDataSet,columns=['Comments'])\n",
    "\n",
    "new_train_df.to_csv('train.csv',index=False,header=False)\n",
    "new_test_df.to_csv('test.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer and Naive Bayes Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orestis/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:450: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = - 0.5 * np.sum(np.log(2. * np.pi * self.sigma_[i, :]))\n",
      "/home/orestis/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:452: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  (self.sigma_[i, :]), 1)\n",
      "/home/orestis/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:452: RuntimeWarning: invalid value encountered in subtract\n",
      "  (self.sigma_[i, :]), 1)\n",
      "/home/orestis/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:450: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = - 0.5 * np.sum(np.log(2. * np.pi * self.sigma_[i, :]))\n",
      "/home/orestis/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:452: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  (self.sigma_[i, :]), 1)\n",
      "/home/orestis/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:452: RuntimeWarning: invalid value encountered in subtract\n",
      "  (self.sigma_[i, :]), 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 60.581655480984345\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jun  4 09:29:45 2020\n",
    "\n",
    "@author: orestis\n",
    "\"\"\"\n",
    "\n",
    "from pandas import DataFrame,read_csv\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#Function to get accuracy of the predicted results\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0\n",
    "\n",
    "TrainDataLocation = './train.csv'\n",
    "TestDataLocation = './test.csv'\n",
    "\n",
    "train_df = pd.read_csv(TrainDataLocation,header=None,names=['Comment','Class'])\n",
    "test_df = pd.read_csv(TestDataLocation,header=None,names=['Comment','Class'])\n",
    "\n",
    "train_comments = train_df['Comment']\n",
    "test_comments = test_df['Comment']\n",
    "\n",
    "train_classes=train_df['Class']\n",
    "test_classes =test_df['Class']\n",
    "\n",
    "\n",
    "#Create a Gaussian Naive Bayes model\n",
    "model = GaussianNB()\n",
    "\n",
    "#Create Train Count Vectorizer\n",
    "TrainCount_Vectorizer = list()\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "predicted_classes=list()\n",
    "#Make the predictions\n",
    "for test_comment in test_comments:\n",
    "    TrainCount_Vectorizer=[]\n",
    "    #tokenize and build vocabulary\n",
    "    vectorizer.fit([test_comment])\n",
    "    for x in train_comments:\n",
    "        comment = [x]\n",
    "        #encode the document\n",
    "        vector = vectorizer.transform(comment)\n",
    "        temp_array = vector.toarray()\n",
    "        TrainCount_Vectorizer.append(temp_array[0])\n",
    "    \n",
    "    #Predict Output\n",
    "    model.fit(TrainCount_Vectorizer,train_classes)\n",
    "    vector = vectorizer.transform([test_comment])\n",
    "    predicted = model.predict(vector.toarray())\n",
    "    predicted_classes.append(predicted)\n",
    "\n",
    "score = accuracy_metric(test_classes, predicted_classes)\n",
    "print('Score:',score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction After removing stopwords and lemmization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7697283311772316\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jun  5 12:56:30 2020\n",
    "\n",
    "@author: orestis\n",
    "\"\"\"\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "DataLocation = './data.csv'\n",
    "\n",
    "df = pd.read_csv(DataLocation,header=None,names=['Comment','Class'])\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(df['Comment'],df['Class'], random_state=1)\n",
    "\n",
    "cv = CountVectorizer(strip_accents='ascii',token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b',lowercase=True,stop_words='english')\n",
    "\n",
    "X_train_cv=cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train_cv, y_train)\n",
    "predictions = naive_bayes.predict(X_test_cv)\n",
    "\n",
    "print('Accuracy score: ',accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores of NaiveBayes,Random Forest,SVM with the use of TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes score:  0.7289780077619664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model_name\n",
       "LinearSVC                 0.764795\n",
       "RandomForestClassifier    0.656098\n",
       "Name: accuracy, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jun  5 12:56:30 2020\n",
    "\n",
    "@author: orestis\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DataLocation = './data.csv'\n",
    "\n",
    "df = pd.read_csv(DataLocation,header=None,names=['Comment','Class'])\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1,2), stop_words='english')\n",
    "\n",
    "features = tfidf.fit_transform(df.Comment).toarray()\n",
    "labels = df.Class\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(df['Comment'],df['Class'], random_state=0)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "X_train_counts=count_vect.fit_transform(X_train)\n",
    "X_test_cv = count_vect.transform(X_test)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "naive_bayes = MultinomialNB()\n",
    "predictions = clf.predict(X_test_cv)\n",
    "\n",
    "print('Naive Bayes score: ',accuracy_score(y_test, predictions))\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "]\n",
    "\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "  model_name = model.__class__.__name__\n",
    "  accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
    "  for fold_idx, accuracy in enumerate(accuracies):\n",
    "    entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "\n",
    "\n",
    "cv_df.groupby('model_name').accuracy.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score of Naive Bayes after lemmazation removing stopwords,Laplace Smoothing,biagrams and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes score:  0.7373868046571799\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jun  5 15:34:22 2020\n",
    "\n",
    "@author: orestis\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import nltk\n",
    "import re\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "DataLocation = './data.csv'\n",
    "\n",
    "first_df = pd.read_csv(DataLocation,header=None,names=['Comment','Class'])\n",
    "\n",
    "comments_biagrams=list()\n",
    "#Create a new list with the bigrams of the comments\n",
    "for i in range(len(first_df['Comment'])):\n",
    "    txt1 = first_df['Comment'][i]\n",
    "    # initializing list  \n",
    "    test_list = [txt1] \n",
    "      \n",
    "    # using list comprehension + enumerate() + split() \n",
    "    # for Bigram formation \n",
    "    res = [(x, i.split()[j + 1]) for i in test_list  \n",
    "           for j, x in enumerate(i.split()) if j < len(i.split()) - 1] \n",
    "    \n",
    "    new_comment = ''\n",
    "    for x in res:\n",
    "        #Create a new comment with the lemmatized biagrams\n",
    "        new_comment = new_comment + lemmatizer.lemmatize(x[0]) + lemmatizer.lemmatize(x[1]) + ' '\n",
    "    comments_biagrams.append(new_comment)\n",
    "\n",
    "#Create a new dataset with the biagrams\n",
    "class_values = first_df['Class']\n",
    "DataSet = list(zip(comments_biagrams,class_values))\n",
    "df = pd.DataFrame(data=DataSet,columns=['Comment','Class'])\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1,2), stop_words='english')\n",
    "\n",
    "features = tfidf.fit_transform(df.Comment).toarray()\n",
    "labels = df.Class\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(df['Comment'],df['Class'], random_state=0)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "X_train_counts=count_vect.fit_transform(X_train)\n",
    "X_test_cv = count_vect.transform(X_test)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB(alpha=1).fit(X_train_tfidf, y_train)#alpha=1 ->Laplace Smoothing\n",
    "\n",
    "predictions = clf.predict(X_test_cv)\n",
    "\n",
    "print('Naive Bayes score: ',accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores of NaiveBayes,Random Forest,SVM with the use of biagrams and TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes score:  0.7373868046571799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model_name\n",
       "LinearSVC                 0.729534\n",
       "RandomForestClassifier    0.656098\n",
       "Name: accuracy, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jun  5 15:34:22 2020\n",
    "\n",
    "@author: orestis\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import nltk\n",
    "import re\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "DataLocation = './data.csv'\n",
    "\n",
    "first_df = pd.read_csv(DataLocation,header=None,names=['Comment','Class'])\n",
    "\n",
    "comments_biagrams=list()\n",
    "#Create a new list with the bigrams of the comments\n",
    "for i in range(len(first_df['Comment'])):\n",
    "    txt1 = first_df['Comment'][i]\n",
    "    # initializing list  \n",
    "    test_list = [txt1] \n",
    "      \n",
    "    # using list comprehension + enumerate() + split() \n",
    "    # for Bigram formation \n",
    "    res = [(x, i.split()[j + 1]) for i in test_list  \n",
    "           for j, x in enumerate(i.split()) if j < len(i.split()) - 1] \n",
    "    \n",
    "    new_comment = ''\n",
    "    for x in res:\n",
    "        #Create a new comment with the lemmatized biagrams\n",
    "        new_comment = new_comment + lemmatizer.lemmatize(x[0]) + lemmatizer.lemmatize(x[1]) + ' '\n",
    "    comments_biagrams.append(new_comment)\n",
    "\n",
    "#Create a new dataset with the biagrams\n",
    "class_values = first_df['Class']\n",
    "DataSet = list(zip(comments_biagrams,class_values))\n",
    "df = pd.DataFrame(data=DataSet,columns=['Comment','Class'])\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1,2), stop_words='english')\n",
    "\n",
    "features = tfidf.fit_transform(df.Comment).toarray()\n",
    "labels = df.Class\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(df['Comment'],df['Class'], random_state=0)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "X_train_counts=count_vect.fit_transform(X_train)\n",
    "X_test_cv = count_vect.transform(X_test)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB(alpha=1).fit(X_train_tfidf, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test_cv)\n",
    "\n",
    "print('Naive Bayes score: ',accuracy_score(y_test, predictions))\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "]\n",
    "\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "  model_name = model.__class__.__name__\n",
    "  accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
    "  for fold_idx, accuracy in enumerate(accuracies):\n",
    "    entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "\n",
    "\n",
    "cv_df.groupby('model_name').accuracy.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
